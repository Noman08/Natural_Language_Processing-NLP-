{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "388ea1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import logging\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cea36ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>v</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001001</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>In the beginning God created the heavens and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001002</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>And the earth was waste and void; and darkness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>And God said, Let there be light: and there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001004</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>And God saw the light, that it was good: and G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001005</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>And God called the light Day, and the darkness...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         b  c  v                                                  t\n",
       "id                                                                 \n",
       "1001001  1  1  1  In the beginning God created the heavens and t...\n",
       "1001002  1  1  2  And the earth was waste and void; and darkness...\n",
       "1001003  1  1  3  And God said, Let there be light: and there wa...\n",
       "1001004  1  1  4  And God saw the light, that it was good: and G...\n",
       "1001005  1  1  5  And God called the light Day, and the darkness..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verse = pd.read_csv('./bible/t_asv.csv', index_col='id', \n",
    "                    dtype={'id': np.int64, 'b': np.int32, 'c': np.int32, 'v': np.int32, 't': object})\n",
    "\n",
    "verse.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6d13050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['In the beginning God created the heavens and the earth.',\n",
       "       'And the earth was waste and void; and darkness was upon the face of the deep: and the Spirit of God moved upon the face of the waters.',\n",
       "       'And God said, Let there be light: and there was light.', ...,\n",
       "       'and if any man shall take away from the words of the book of this prophecy, God shall take away his part from the tree of life, and out of the holy city, which are written in this book.',\n",
       "       'He who testifieth these things saith, Yea: I come quickly. Amen: come, Lord Jesus.',\n",
       "       'The grace of the Lord Jesus be with the saints. Amen.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verse = verse[\"t\"].values\n",
    "verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "324eff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_vec = [nltk.word_tokenize(title) for title in verse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "98160b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def in_list(item,L):\n",
    "    for i in L:\n",
    "        if item in i:\n",
    "            return L.index(i)\n",
    "    return -1\n",
    "p = in_list('In', verse_vec)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a1e5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "verse_vec = [[w.lower() for w in line] for line in verse_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f421e30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['in',\n",
       "  'the',\n",
       "  'beginning',\n",
       "  'god',\n",
       "  'created',\n",
       "  'the',\n",
       "  'heavens',\n",
       "  'and',\n",
       "  'the',\n",
       "  'earth',\n",
       "  '.'],\n",
       " ['and',\n",
       "  'the',\n",
       "  'earth',\n",
       "  'was',\n",
       "  'waste',\n",
       "  'and',\n",
       "  'void',\n",
       "  ';',\n",
       "  'and',\n",
       "  'darkness',\n",
       "  'was',\n",
       "  'upon',\n",
       "  'the',\n",
       "  'face',\n",
       "  'of',\n",
       "  'the',\n",
       "  'deep',\n",
       "  ':',\n",
       "  'and',\n",
       "  'the',\n",
       "  'spirit',\n",
       "  'of',\n",
       "  'god',\n",
       "  'moved',\n",
       "  'upon',\n",
       "  'the',\n",
       "  'face',\n",
       "  'of',\n",
       "  'the',\n",
       "  'waters',\n",
       "  '.']]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verse_vec[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c72bfa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 20:12:24,685 : INFO : collecting all words and their counts\n",
      "2022-05-09 20:12:24,686 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-05-09 20:12:24,756 : INFO : PROGRESS: at sentence #10000, processed 324578 words, keeping 6659 word types\n",
      "2022-05-09 20:12:24,810 : INFO : PROGRESS: at sentence #20000, processed 598525 words, keeping 10243 word types\n",
      "2022-05-09 20:12:24,854 : INFO : PROGRESS: at sentence #30000, processed 886820 words, keeping 12616 word types\n",
      "2022-05-09 20:12:24,863 : INFO : collected 12860 word types from a corpus of 919886 raw words and 31103 sentences\n",
      "2022-05-09 20:12:24,865 : INFO : Creating a fresh vocabulary\n",
      "2022-05-09 20:12:24,893 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 3647 unique words (28.359253499222394%% of original 12860, drops 9213)', 'datetime': '2022-05-09T20:12:24.893363', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-05-09 20:12:24,894 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 895215 word corpus (97.31803723504869%% of original 919886, drops 24671)', 'datetime': '2022-05-09T20:12:24.894330', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-05-09 20:12:24,922 : INFO : deleting the raw counts dictionary of 12860 items\n",
      "2022-05-09 20:12:24,924 : INFO : sample=0.001 downsamples 60 most-common words\n",
      "2022-05-09 20:12:24,925 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 550293.7084885394 word corpus (61.5%% of prior 895215)', 'datetime': '2022-05-09T20:12:24.925248', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-05-09 20:12:24,978 : INFO : estimated required memory for 3647 words and 5000 dimensions: 147703500 bytes\n",
      "2022-05-09 20:12:24,978 : INFO : resetting layer weights\n",
      "2022-05-09 20:12:25,073 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-05-09T20:12:25.073892', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-05-09 20:12:25,073 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 3647 vocabulary and 5000 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2022-05-09T20:12:25.073892', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-05-09 20:12:26,300 : INFO : EPOCH 1 - PROGRESS: at 9.58% examples, 43699 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:27,303 : INFO : EPOCH 1 - PROGRESS: at 19.73% examples, 50770 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:28,310 : INFO : EPOCH 1 - PROGRESS: at 25.38% examples, 45888 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:29,356 : INFO : EPOCH 1 - PROGRESS: at 32.92% examples, 45684 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:30,564 : INFO : EPOCH 1 - PROGRESS: at 46.48% examples, 48403 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:31,773 : INFO : EPOCH 1 - PROGRESS: at 61.78% examples, 50538 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:32,975 : INFO : EPOCH 1 - PROGRESS: at 69.02% examples, 48970 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:34,109 : INFO : EPOCH 1 - PROGRESS: at 77.02% examples, 48130 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:35,119 : INFO : EPOCH 1 - PROGRESS: at 86.88% examples, 48145 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:36,060 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-05-09 20:12:36,081 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-05-09 20:12:36,102 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-05-09 20:12:36,151 : INFO : EPOCH 1 - PROGRESS: at 100.00% examples, 49765 words/s, in_qsize 0, out_qsize 1\n",
      "2022-05-09 20:12:36,151 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-05-09 20:12:36,152 : INFO : EPOCH - 1 : training on 919886 raw words (550803 effective words) took 11.1s, 49760 effective words/s\n",
      "2022-05-09 20:12:37,206 : INFO : EPOCH 2 - PROGRESS: at 6.54% examples, 33950 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:38,235 : INFO : EPOCH 2 - PROGRESS: at 13.80% examples, 36960 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:39,462 : INFO : EPOCH 2 - PROGRESS: at 25.38% examples, 44774 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:40,590 : INFO : EPOCH 2 - PROGRESS: at 37.03% examples, 49161 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:41,609 : INFO : EPOCH 2 - PROGRESS: at 47.85% examples, 49772 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:42,647 : INFO : EPOCH 2 - PROGRESS: at 59.93% examples, 50172 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:43,651 : INFO : EPOCH 2 - PROGRESS: at 67.22% examples, 49941 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:44,705 : INFO : EPOCH 2 - PROGRESS: at 75.79% examples, 50074 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:45,880 : INFO : EPOCH 2 - PROGRESS: at 86.91% examples, 49634 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:46,806 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-05-09 20:12:46,847 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-05-09 20:12:46,893 : INFO : EPOCH 2 - PROGRESS: at 99.10% examples, 50712 words/s, in_qsize 1, out_qsize 1\n",
      "2022-05-09 20:12:46,894 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-05-09 20:12:46,987 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-05-09 20:12:46,987 : INFO : EPOCH - 2 : training on 919886 raw words (550238 effective words) took 10.8s, 50815 effective words/s\n",
      "2022-05-09 20:12:48,392 : INFO : EPOCH 3 - PROGRESS: at 9.53% examples, 37971 words/s, in_qsize 6, out_qsize 1\n",
      "2022-05-09 20:12:49,535 : INFO : EPOCH 3 - PROGRESS: at 17.93% examples, 39689 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:50,555 : INFO : EPOCH 3 - PROGRESS: at 25.38% examples, 41635 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:51,561 : INFO : EPOCH 3 - PROGRESS: at 35.07% examples, 45230 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:52,610 : INFO : EPOCH 3 - PROGRESS: at 41.85% examples, 43983 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:53,649 : INFO : EPOCH 3 - PROGRESS: at 57.02% examples, 46322 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:54,900 : INFO : EPOCH 3 - PROGRESS: at 65.26% examples, 45800 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:56,106 : INFO : EPOCH 3 - PROGRESS: at 72.66% examples, 44983 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:57,135 : INFO : EPOCH 3 - PROGRESS: at 84.45% examples, 46358 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:12:58,331 : INFO : EPOCH 3 - PROGRESS: at 96.70% examples, 46895 words/s, in_qsize 4, out_qsize 0\n",
      "2022-05-09 20:12:58,372 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-05-09 20:12:58,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-05-09 20:12:58,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-05-09 20:12:58,525 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-05-09 20:12:58,526 : INFO : EPOCH - 3 : training on 919886 raw words (550576 effective words) took 11.5s, 47742 effective words/s\n",
      "2022-05-09 20:12:59,660 : INFO : EPOCH 4 - PROGRESS: at 5.44% examples, 26162 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:00,872 : INFO : EPOCH 4 - PROGRESS: at 13.80% examples, 32793 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:02,130 : INFO : EPOCH 4 - PROGRESS: at 21.78% examples, 34451 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:03,145 : INFO : EPOCH 4 - PROGRESS: at 30.87% examples, 39914 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:04,412 : INFO : EPOCH 4 - PROGRESS: at 40.84% examples, 40929 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 20:13:05,446 : INFO : EPOCH 4 - PROGRESS: at 54.20% examples, 42835 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:06,535 : INFO : EPOCH 4 - PROGRESS: at 64.35% examples, 44484 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:07,801 : INFO : EPOCH 4 - PROGRESS: at 72.66% examples, 44228 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:08,880 : INFO : EPOCH 4 - PROGRESS: at 85.75% examples, 46039 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:09,895 : INFO : EPOCH 4 - PROGRESS: at 92.85% examples, 45143 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:10,347 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-05-09 20:13:10,354 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-05-09 20:13:10,391 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-05-09 20:13:10,439 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-05-09 20:13:10,440 : INFO : EPOCH - 4 : training on 919886 raw words (549881 effective words) took 11.9s, 46196 effective words/s\n",
      "2022-05-09 20:13:11,679 : INFO : EPOCH 5 - PROGRESS: at 9.58% examples, 43141 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:12,717 : INFO : EPOCH 5 - PROGRESS: at 17.93% examples, 44460 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:13,720 : INFO : EPOCH 5 - PROGRESS: at 25.38% examples, 45272 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:14,775 : INFO : EPOCH 5 - PROGRESS: at 32.60% examples, 45301 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:16,106 : INFO : EPOCH 5 - PROGRESS: at 40.84% examples, 42539 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:17,159 : INFO : EPOCH 5 - PROGRESS: at 52.71% examples, 43205 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:18,415 : INFO : EPOCH 5 - PROGRESS: at 61.78% examples, 42420 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:19,762 : INFO : EPOCH 5 - PROGRESS: at 69.02% examples, 41447 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:20,809 : INFO : EPOCH 5 - PROGRESS: at 73.62% examples, 40123 words/s, in_qsize 8, out_qsize 0\n",
      "2022-05-09 20:13:21,898 : INFO : EPOCH 5 - PROGRESS: at 80.77% examples, 39473 words/s, in_qsize 8, out_qsize 0\n",
      "2022-05-09 20:13:23,295 : INFO : EPOCH 5 - PROGRESS: at 86.88% examples, 37578 words/s, in_qsize 7, out_qsize 0\n",
      "2022-05-09 20:13:24,396 : INFO : EPOCH 5 - PROGRESS: at 96.70% examples, 38120 words/s, in_qsize 4, out_qsize 0\n",
      "2022-05-09 20:13:24,401 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2022-05-09 20:13:24,441 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-05-09 20:13:24,469 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-05-09 20:13:24,506 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-05-09 20:13:24,508 : INFO : EPOCH - 5 : training on 919886 raw words (550504 effective words) took 14.1s, 39155 effective words/s\n",
      "2022-05-09 20:13:24,511 : INFO : Word2Vec lifecycle event {'msg': 'training on 4599430 raw words (2752002 effective words) took 59.4s, 46301 effective words/s', 'datetime': '2022-05-09T20:13:24.511457', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-05-09 20:13:24,513 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=3647, vector_size=5000, alpha=0.025)', 'datetime': '2022-05-09T20:13:24.513451', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "C:\\Users\\nn\\AppData\\Local\\Temp/ipykernel_19200/2600498417.py:20: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n",
      "2022-05-09 20:13:24,609 : WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
      "2022-05-09 20:13:24,626 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'bible_word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-05-09T20:13:24.626668', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-05-09 20:13:24,628 : INFO : storing np array 'vectors' to bible_word2vec.model.wv.vectors.npy\n",
      "2022-05-09 20:13:24,949 : INFO : storing np array 'syn1neg' to bible_word2vec.model.syn1neg.npy\n",
      "2022-05-09 20:13:25,331 : INFO : not storing attribute cum_table\n",
      "2022-05-09 20:13:25,339 : INFO : saved bible_word2vec.model\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# training word2vec model\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "num_features = 5000    # Word vector dimensionality                      \n",
    "min_word_count = 10   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "bible = verse_vec\n",
    "\n",
    "model = word2vec.Word2Vec(bible, workers=num_workers, \\\n",
    "                        vector_size=num_features, min_count = min_word_count, \\\n",
    "                        window = context, sample = downsampling)\n",
    "model.init_sims(replace=True)\n",
    "model.save(\"bible_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "828135d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('most', 0.6912201642990112),\n",
       " ('glory', 0.6666838526725769),\n",
       " ('established', 0.649179220199585),\n",
       " ('sacrifice', 0.6401773691177368),\n",
       " ('ever', 0.6295251846313477),\n",
       " ('hosts', 0.6253499984741211),\n",
       " ('everlasting', 0.6247296333312988),\n",
       " ('praise', 0.6096181869506836),\n",
       " ('statute', 0.6056853532791138),\n",
       " ('lacking', 0.5790976881980896)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"holy\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4d92da9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('herds', 0.7508175373077393),\n",
       " ('few', 0.742457389831543),\n",
       " ('provinces', 0.7401953339576721),\n",
       " ('persons', 0.7302664518356323),\n",
       " ('flocks', 0.7294304966926575),\n",
       " ('virgins', 0.7183959484100342),\n",
       " ('valor', 0.7167403697967529),\n",
       " ('men', 0.713136613368988),\n",
       " ('ethiopians', 0.6980056762695312),\n",
       " ('higher', 0.690645694732666)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"women\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "76a33c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('darkness', 0.8008269667625427),\n",
       " ('fruit', 0.7168245315551758),\n",
       " ('moon', 0.7095617055892944),\n",
       " ('rain', 0.7095038890838623),\n",
       " ('paths', 0.6709146499633789),\n",
       " ('dew', 0.6701098680496216),\n",
       " ('shadow', 0.6497399806976318),\n",
       " ('just', 0.6442381739616394),\n",
       " ('heavens', 0.642227053642273),\n",
       " ('sown', 0.6301502585411072)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"light\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "518a3ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('john', 0.7623591423034668),\n",
       " ('peter', 0.7215086221694946),\n",
       " ('elijah', 0.7126917839050293),\n",
       " ('paul', 0.6932657957077026),\n",
       " ('isaiah', 0.6793155670166016),\n",
       " ('lord', 0.678869903087616),\n",
       " ('samuel', 0.6737868785858154),\n",
       " ('prophet', 0.6701518297195435),\n",
       " ('answered', 0.6530582904815674),\n",
       " ('daniel', 0.6504835486412048)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"jesus\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "53fd199e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jesus', 0.7337614893913269),\n",
       " ('esther', 0.6782093048095703),\n",
       " ('peter', 0.6725742816925049),\n",
       " ('john', 0.6639114618301392),\n",
       " ('elijah', 0.6300449967384338),\n",
       " ('answered', 0.6278935670852661),\n",
       " ('angel', 0.6250754594802856),\n",
       " ('mordecai', 0.6212992668151855),\n",
       " ('well', 0.6045417785644531),\n",
       " ('queen', 0.5918430089950562)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "express =  model.wv['jesus'] - model.wv['man'] + model.wv['woman']\n",
    "model.wv.most_similar([express]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2be422ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('money', 0.8048887848854065),\n",
       " ('sojourner', 0.7585711479187012),\n",
       " ('fatherless', 0.706995964050293),\n",
       " ('bottle', 0.7062492966651917),\n",
       " ('friend', 0.7016578912734985),\n",
       " ('wine', 0.6925674676895142),\n",
       " ('raiment', 0.6878551840782166),\n",
       " ('estimation', 0.68038010597229),\n",
       " ('firstling', 0.6701173782348633),\n",
       " ('fair', 0.6689985990524292)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "express =  model.wv['money'] - model.wv['evil'] + model.wv['good']\n",
    "model.wv.most_similar([express]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "331251ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 0.7677114605903625),\n",
       " ('him', 0.534227192401886),\n",
       " ('himself', 0.5123739838600159),\n",
       " ('king', 0.46371322870254517),\n",
       " ('death', 0.41993841528892517),\n",
       " ('man', 0.4152510464191437),\n",
       " ('pharaoh', 0.38624608516693115),\n",
       " ('hand', 0.37442007660865784),\n",
       " ('jehovah', 0.3670368492603302),\n",
       " ('his', 0.36421963572502136)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "express =  model.wv['king'] - model.wv['queen'] + model.wv['he']\n",
    "model.wv.most_similar([express]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d339131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
